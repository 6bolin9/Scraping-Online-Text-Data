{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#lets write a Simple script \n",
    "#to get the 20 words and their frequency percentage \n",
    "#with highest frequency in an English Wikipedia article. \n",
    "#applications are recommender systems, chatbots and NLP, sentiment analysis,\n",
    "#data visualization,\n",
    "#market research\n",
    "\n",
    "#import dependencies\n",
    "#Beautiful Soup is a Python library \n",
    "#for pulling data out of HTML and XML files.从网站取出来的数据是HTML，想把数据转化\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Requests is one of the most downloaded \n",
    "#Python packages of all time, \n",
    "#pulling in over 7,000,000 downloads every month.\n",
    "#HTTP library for pulling pushing and authenticating 抓取数据的\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#lets you do Regular expression operations\n",
    "#special text string for describing a search pattern.\n",
    "#find and replace：regular expressions对文档的文字进行一些处理\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The operator module exports a \n",
    "#set of efficient functions \n",
    "#corresponding to the intrinsic operators of Python.\n",
    "#comparison, addition, greater than less then 加减之类 更易理解的处理\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#parses解析 json, formats it，提取的format是json\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The module provides just one function, \n",
    "#tabulate, which takes a list of lists or another \n",
    "#tabular data type as the first argument, \n",
    "#and outputs a nicely formatted plain-text table:更好的展示城table\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#system calls, dealw with user arguments： 这里的user input：What's the wikipidia artical we want to get\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of common stop words various languages like the #words are not matter\n",
    "from stop_words import get_stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get the words\n",
    "def getWordList(url):\n",
    "    word_list = []\n",
    "    #raw data\n",
    "    source_code = requests.get(url)\n",
    "    #convert to text\n",
    "    plain_text = source_code.text\n",
    "    #lxml format\n",
    "    soup = BeautifulSoup(plain_text,'lxml')\n",
    "\n",
    "    #find the words in paragraph tag\n",
    "    for text in soup.findAll('p'):\n",
    "        if text.text is None:\n",
    "            continue\n",
    "        #content\n",
    "        content = text.text\n",
    "        #lowercase and split into an array\n",
    "        words = content.lower().split()\n",
    "\n",
    "        #for each word\n",
    "        for word in words:\n",
    "            #remove non-chars\n",
    "            cleaned_word = clean_word(word)\n",
    "            #if there is still something there\n",
    "            if len(cleaned_word) > 0:\n",
    "                #add it to our word list\n",
    "                word_list.append(cleaned_word)\n",
    "\n",
    "    return word_list\n",
    "\n",
    "\n",
    "#clean word with regex\n",
    "def clean_word(word):\n",
    "    cleaned_word = re.sub('[^A-Za-z]+', '', word)\n",
    "    return cleaned_word\n",
    "\n",
    "\n",
    "def createFrquencyTable(word_list):\n",
    "    #word count\n",
    "    word_count = {}\n",
    "    for word in word_list:\n",
    "        #index is the word\n",
    "        if word in word_count:\n",
    "            word_count[word] += 1\n",
    "        else:\n",
    "            word_count[word] = 1\n",
    "\n",
    "    return word_count\n",
    "\n",
    "#remove stop words\n",
    "def remove_stop_words(frequency_list):\n",
    "    stop_words = get_stop_words('en')\n",
    "\n",
    "    temp_list = []\n",
    "    for key,value in frequency_list:\n",
    "        if key not in stop_words:\n",
    "            temp_list.append([key, value])\n",
    "\n",
    "    return temp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#access wiki API. json format. query it for data. search tyep. shows list of possibilities \n",
    "#第一个URL，Joson format---action=search(我们是从网页上queer data from web)---list type=search:我们type的字是去寻找一系列list---\n",
    "#srsearch--我们自己加入的article的name， ex 加入Batman，会出现相关的文章的title的list\n",
    "wikipedia_api_link = \"https://en.wikipedia.org/w/api.php?format=json&action=query&list=search&srsearch=\"\n",
    "wikipedia_link = \"https://en.wikipedia.org/wiki/\"\n",
    "#第二个URL只是网站的网址"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#if the search word is too small, throw an error\n",
    "if(len(sys.argv) < 2):\n",
    "    print(\"Enter valid string\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get the search word  这里不太懂过\n",
    "string_query = sys.argv[1]\n",
    "\n",
    "#to remove stop words or not  True代表表示去掉stop words，如果长于2个\n",
    "if(len(sys.argv) > 2):\n",
    "    search_mode = True\n",
    "else:\n",
    "    search_mode = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create our URL 建立自己的网址\n",
    "url = wikipedia_api_link + string_query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Word           |   Frequency |   Frequency Percentage |\n",
      "|----------------+-------------+------------------------|\n",
      "| municipality   |          12 |                 5.4054 |\n",
      "| may            |           6 |                 2.7027 |\n",
      "| state          |           5 |                 2.2523 |\n",
      "| communes       |           4 |                 1.8018 |\n",
      "| latin          |           4 |                 1.8018 |\n",
      "| municipalities |           4 |                 1.8018 |\n",
      "| tax            |           4 |                 1.8018 |\n",
      "| jurisdiction   |           3 |                 1.3514 |\n",
      "| administrative |           3 |                 1.3514 |\n",
      "| communities    |           3 |                 1.3514 |\n",
      "| term           |           3 |                 1.3514 |\n",
      "| also           |           3 |                 1.3514 |\n",
      "| derived        |           3 |                 1.3514 |\n",
      "| languages      |           2 |                 0.9009 |\n",
      "| comun          |           2 |                 0.9009 |\n",
      "| frenchspeaking |           2 |                 0.9009 |\n",
      "| countries      |           2 |                 0.9009 |\n",
      "| moldova        |           2 |                 0.9009 |\n",
      "| small          |           2 |                 0.9009 |\n",
      "| spanish        |           2 |                 0.9009 |\n"
     ]
    }
   ],
   "source": [
    "#try-except block. simple way to deal with exceptions \n",
    "#great for HTTP requests\n",
    "try:\n",
    "    #use requests to retrieve raw data from wiki API URL we\n",
    "    #just constructed\n",
    "    response = requests.get(url)\n",
    "\n",
    "    #format that data as a JSON dictionary 转变成我们想要的format\n",
    "    data = json.loads(response.content.decode(\"utf-8\"))\n",
    "\n",
    "    #page title, first option\n",
    "    #show this in web browser\n",
    "    wikipedia_page_tag = data['query']['search'][0]['title']\n",
    "\n",
    "    #get actual wiki page based on retrieved title\n",
    "    url = wikipedia_link + wikipedia_page_tag\n",
    "    \n",
    "    #get list of words from that page\n",
    "    page_word_list = getWordList(url)\n",
    "    #create table of word counts, dictionary\n",
    "    page_word_count = createFrquencyTable(page_word_list)\n",
    "    #sort the table by the frequency count\n",
    "    sorted_word_frequency_list = sorted(page_word_count.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    #remove stop words if the user specified，之前的stopword有search_mode= True\n",
    "    if(search_mode):\n",
    "        sorted_word_frequency_list = remove_stop_words(sorted_word_frequency_list)\n",
    "\n",
    "    #sum the total words to calculate frequencies   \n",
    "    total_words_sum = 0\n",
    "    for key,value in sorted_word_frequency_list:\n",
    "        total_words_sum = total_words_sum + value\n",
    "\n",
    "    #just get the top 20 words\n",
    "    if len(sorted_word_frequency_list) > 20:\n",
    "        sorted_word_frequency_list = sorted_word_frequency_list[:20]\n",
    "\n",
    "    #create our final list which contains words, frequency (word count), percentage\n",
    "    final_list = []\n",
    "    for key,value in sorted_word_frequency_list:\n",
    "        percentage_value = float(value * 100) / total_words_sum\n",
    "        final_list.append([key, value, round(percentage_value, 4)])\n",
    "\n",
    "    #headers before the table\n",
    "    print_headers = ['Word', 'Frequency', 'Frequency Percentage']\n",
    "\n",
    "    #print the table with tabulate\n",
    "    print(tabulate(final_list, headers=print_headers, tablefmt='orgtbl'))\n",
    "    \n",
    "    #throw an exception in case it breaks\n",
    "except requests.exceptions.Timeout:\n",
    "    print(\"The server didn't respond. Please, try again later.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
